---
layout: post
tags: [lucene, solr]
---

> 이 문서는 가리사니 개발자 포럼에 올렸던 글의 백업 파일입니다.
오래된 문서가 많아 현재 상황과 맞지 않을 수 있습니다.


한글 형태소를 사용하고 있는데 dataimport 시에 데이터가 덜 들어갔는데 녹색화면이 뜨고 완료되었다고 하면서 실제 열의 갯수와 다른결과를 보여주거나, 진행도중에 멈춰버리는 경우 이 문서를 참조해보세요.

어제 (오늘새벽) 까지 지인의 초대량 데이터를 솔라에 입력시켜 주었는데... 문제는 수십여개의 스키마중 몇개정도는 몇만개 정도에서 dataimport 가 멈춰버리는 겁니다.
처음엔  db-data-config.xml entity에 onError 옵션을 줬습니다.
(데이터가 많다보니 일단 패스라도 시키려고...)

하지만 특정 갯수에서 멈춰 dataimport 의 onError 까지 무시하며 진행이 되지 않기에 DB에서 해당 글을 확인하니.. 한글을 띄어쓰기없이 딱봐도 수천자는 넘어보이게 써놨습니다.
예를들어 가나다라마바사가나다라마바사(이런식으로 수천자...이상..)

필자의 예상으로는 한글 형태소 사전이 합성어를 분리를 위해 사전을 찾아보고 해당 글자의 길이가 비정상적으로 길다보니 시간을 소모하다 다운되는 것 같습니다.
그래서 형태소를 검사하기전 단어하나가 50글자가 넘어가는 경우는 필터하기로했습니다.
(50자가 넘어가면 일반적인 단어로 보긴 힘든 것 같습니다. : 필자기준..)
아래와 같이 LengthFilterFactory 를 추가해줍니다.
(다들 아시겠지만 필터는 써놓은 순서대로 실행되니 반드시 한글 형태소 보다 앞에 있어야합니다.)
``` java
<fieldType name="ko" class="solr.TextField">
		<analyzer type="index">
			<filter class="solr.LengthFilterFactory" min="1" max="50" />
			<tokenizer class="org.apache.lucene.analysis.ko.KoreanTokenizerFactory" />
			<filter class="solr.LowerCaseFilterFactory" />
			<filter class="solr.ClassicFilterFactory" />
			<filter class="org.apache.lucene.analysis.ko.KoreanFilterFactory" hasOrigin="true" hasCNoun="true" bigrammable="false" />
			<filter class="org.apache.lucene.analysis.ko.HanjaMappingFilterFactory" />
			<filter class="org.apache.lucene.analysis.ko.PunctuationDelimitFilterFactory" />
			<filter class="solr.StopFilterFactory" words="stopwords.txt" ignoreCase="true" />
		</analyzer>
		...
```

그리고 실행하니!! 오류없이 모두 실행됩니다.!!!! 만세!!!